# Repository Cleanup Plan

## Current State (Messy!)

### Duplicate/Fragmented Outputs:
- `visusualizations/` (typo!) - Old fragmented plots (23 files)
- `visualizations/` - New unified plots (5 files) ✅ KEEP
- `diagnostics/checkpoint_metrics/` - Old fragmented reports (4 reports + many CSVs)
- `diagnostics/trajectory_analysis/` - New unified analysis ✅ KEEP

### Duplicate Scripts:
- `compute_advanced_metrics.py` - Old version, superseded by wizard
- `visualize_checkpoint_metrics.py` - Old GRU128-only version
- `visualize_factorial_analysis.py` - Old separate factorial plots
- `visualize_with_loss.py` - Old per-model loss overlays
- `run_checkpoint_metrics_wizard.sh` - Old metrics-only wizard
- `summarize_checkpoint_metrics.py` - Old summarization

**NEW UNIFIED SYSTEM** (✅ KEEP):
- `analyze_trajectories_wizard.sh` - Master wizard
- `visualize_unified.py` - Unified visualization
- `generate_report.py` - Unified report generator
- `compute_checkpoint_metrics.py` - Core metrics (called by wizard)

---

## Cleanup Actions

### 1. Delete Old Outputs
```bash
# Remove typo directory and old fragmented outputs
rm -rf visusualizations/
rm -rf diagnostics/checkpoint_metrics/
```

### 2. Archive (Don't Delete) Old Scripts
```bash
mkdir -p scripts/archived
mv scripts/compute_advanced_metrics.py scripts/archived/
mv scripts/visualize_checkpoint_metrics.py scripts/archived/
mv scripts/visualize_factorial_analysis.py scripts/archived/
mv scripts/visualize_with_loss.py scripts/archived/
mv scripts/run_checkpoint_metrics_wizard.sh scripts/archived/
mv scripts/summarize_checkpoint_metrics.py scripts/archived/
```

### 3. Keep Essential Scripts

**Active Analysis:**
- `scripts/analyze_trajectories_wizard.sh` ⭐ **Main entry point**
- `scripts/visualize_unified.py`
- `scripts/generate_report.py`
- `scripts/compute_checkpoint_metrics.py`

**Other Utilities (Keep):**
- `scripts/analyze_weight_embeddings.py` - For UMAP/t-SNE (we'll discuss this!)
- `scripts/run_embedding_wizard.sh`
- Training scripts (`train_all_*.sh`)
- Dataset generation (`generate_*_dataset.py`)
- Export utilities (`export_model_onnx.py`)

### 4. Update .gitignore
```
# Analysis outputs (regenerable)
diagnostics/
visualizations/
*.csv
*.png

# Keep only source code and documentation
!README.md
!ANALYSIS_REPORT.md

# Python
__pycache__/
*.pyc
.venv/
*.egg-info/

# Jupyter
.ipynb_checkpoints/

# OS
.DS_Store
```

### 5. Clean Documentation
- Delete: `ANALYSIS_COMPLETE.md` (duplicates report)
- Keep: Main README + unified report in diagnostics/

---

## Final Clean Structure

```
weight-trajectories/
├── README.md                          # Project overview
├── scripts/
│   ├── analyze_trajectories_wizard.sh ⭐ Main analysis
│   ├── visualize_unified.py
│   ├── generate_report.py
│   ├── compute_checkpoint_metrics.py
│   ├── analyze_weight_embeddings.py   # For representation analysis
│   ├── run_embedding_wizard.sh
│   ├── train_all_*.sh                 # Training utilities
│   └── archived/                      # Old versions
├── diagnostics/
│   └── trajectory_analysis/           ✅ Generated by wizard
│       ├── ANALYSIS_REPORT.md         ⭐ Main findings
│       ├── *.csv                      # Metrics
│       └── trajectory_summary.csv
├── visualizations/                    ✅ Generated by wizard
│   ├── factorial_heatmaps.png         # 5 unified plots
│   └── ...
├── checkpoints/                       # Training outputs
└── .gitignore                         # Updated
```

---

## What Gets Regenerated

When you run:
```bash
bash scripts/analyze_trajectories_wizard.sh
```

It automatically creates:
- `diagnostics/trajectory_analysis/` - All metrics + report
- `visualizations/` - All plots

So these should be in `.gitignore` and regenerated on demand!
