#!/usr/bin/env python3
"""
Compute mutual information between GRU hidden states and board-derived features.

Consumes hidden-state samples generated by scripts/extract_gru_dynamics.py and
writes per-model/per-epoch MI tables plus summary visualisations.
"""

from __future__ import annotations

import argparse
import json
from pathlib import Path
from typing import Dict, Iterable, List, Tuple
import os
import concurrent.futures as cf
import time

import numpy as np
import pandas as pd

import matplotlib

matplotlib.use("Agg")
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.feature_selection import mutual_info_classif, mutual_info_regression


CLASSIFICATION_FEATURES = {
    "current_player",
    "immediate_win_current",
    "immediate_win_opponent",
    "three_in_row_current",
    "three_in_row_opponent",
}

REGRESSION_FEATURES = {
    "move_index",
    "yellow_count",
    "red_count",
    "piece_diff",
    "valid_moves",
    "center_control_current",
    "center_control_opponent",
}

DEFAULT_FEATURES = sorted(CLASSIFICATION_FEATURES | REGRESSION_FEATURES)


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="Mutual information analysis for GRU hidden states."
    )
    parser.add_argument(
        "--analysis-dir",
        default="diagnostics/gru_observability",
        help="Directory containing hidden_samples produced by extract_gru_dynamics.py",
    )
    parser.add_argument(
        "--features",
        nargs="+",
        default=DEFAULT_FEATURES,
        help="Feature names to evaluate (must match hidden_samples feature_names).",
    )
    parser.add_argument(
        "--max-samples",
        type=int,
        default=4000,
        help="Max number of samples per epoch to use when computing MI.",
    )
    parser.add_argument(
        "--seed",
        type=int,
        default=37,
        help="Random seed for subsampling.",
    )
    parser.add_argument(
        "--output-dir",
        default="visualizations/gru_observability",
        help="Directory where CSV and figures will be written.",
    )
    parser.add_argument(
        "--progress-interval",
        type=int,
        default=20,
        help="Print progress every N computations (>=1).",
    )
    parser.add_argument(
        "--workers",
        type=int,
        default=max(1, min(4, (os.cpu_count() or 2))),
        help="Number of parallel workers for MI tasks (>=1).",
    )
    args, _ = parser.parse_known_args()
    return args


def parse_model_name(name: str) -> Dict[str, int]:
    parts = {}
    for token in name.split("_"):
        if token.startswith("k"):
            parts["kernel"] = int(token[1:])
        elif token.startswith("c"):
            parts["channels"] = int(token[1:])
        elif token.startswith("gru"):
            parts["gru"] = int(token[3:])
    return parts


def list_hidden_files(model_dir: Path) -> List[Tuple[int, Path]]:
    hidden_dir = model_dir / "hidden_samples"
    if not hidden_dir.exists():
        return []
    files = []
    for path in hidden_dir.glob("epoch_*.npz"):
        try:
            epoch = int(path.stem.split("_")[-1])
        except ValueError:
            continue
        files.append((epoch, path))
    files.sort(key=lambda item: item[0])
    return files


def _load_training_history_best_saved_epoch(model_name: str, analysis_dir: Path) -> Tuple[int | None, int | None]:
    """
    Given a model name (matching a directory under both analysis_dir and checkpoints/),
    return a tuple (best_saved_epoch, final_saved_epoch) based on checkpoints/<model>/training_history.json.

    - best_saved_epoch is the epoch in "epochs_saved" with the lowest val_loss at that epoch index.
    - final_saved_epoch is max(epochs_saved) if present, otherwise the max epoch seen in hidden_samples.

    If the history file is missing, fall back to inferring from hidden_samples under analysis_dir/<model>/hidden_samples.
    """
    try:
        # Resolve history path even if checkpoint directories are timestamped
        history_path = Path("checkpoints") / model_name / "training_history.json"
        if not history_path.exists():
            candidates = sorted(Path("checkpoints").glob(f"{model_name}_*/training_history.json"))
            if candidates:
                history_path = max(candidates, key=lambda p: (p.stat().st_mtime, str(p)))
        if history_path.exists():
            with history_path.open("r") as f:
                hist = json.load(f)
            val_loss = hist.get("val_loss", [])
            epochs_saved = hist.get("epochs_saved")
            if not epochs_saved:
                # Fallback: infer from available hidden_samples
                model_dir = analysis_dir / model_name
                files = list_hidden_files(model_dir)
                epochs_saved = [e for e, _ in files]
            best_e = None
            best_v = float("inf")
            for e in epochs_saved or []:
                idx = int(e) - 1
                if 0 <= idx < len(val_loss):
                    v = val_loss[idx]
                    if v < best_v:
                        best_v = v
                        best_e = int(e)
            final_e = int(max(epochs_saved)) if epochs_saved else None
            return best_e, final_e
    except Exception:
        pass
    # Last resort: infer both from hidden_samples only
    files = list_hidden_files(analysis_dir / model_name)
    if not files:
        return None, None
    epochs = [e for e, _ in files]
    return (min(epochs) if epochs else None), (max(epochs) if epochs else None)


def load_hidden_samples(
    npz_path: Path, max_samples: int, rng: np.random.Generator
) -> Tuple[np.ndarray, np.ndarray, List[str]]:
    data = np.load(npz_path)
    hidden = data["hidden"]
    features = data["features"]
    feature_names = [str(name) for name in data["feature_names"]]

    if hidden.shape[0] == 0:
        return hidden, features, feature_names

    max_count = min(max_samples, hidden.shape[0])
    if hidden.shape[0] > max_count:
        indices = rng.choice(hidden.shape[0], size=max_count, replace=False)
        hidden = hidden[indices]
        features = features[indices]

    hidden, features = clean_hidden_features(hidden, features)
    return hidden, features, feature_names


def clean_hidden_features(
    hidden: np.ndarray, features: np.ndarray
) -> Tuple[np.ndarray, np.ndarray]:
    if hidden.size == 0:
        return hidden, features

    mask_hidden = np.isfinite(hidden).all(axis=1)
    mask_features = np.isfinite(features).all(axis=1)
    mask = mask_hidden & mask_features
    hidden = hidden[mask]
    features = features[mask]

    if hidden.shape[0] == 0:
        return hidden, features

    try:
        _, unique_idx = np.unique(hidden, axis=0, return_index=True)
        if unique_idx.size < hidden.shape[0]:
            unique_idx = np.sort(unique_idx)
            hidden = hidden[unique_idx]
            features = features[unique_idx]
    except TypeError:
        seen = {}
        keep_hidden = []
        keep_features = []
        for vec, feat in zip(hidden, features):
            key = tuple(vec.tolist())
            if key in seen:
                continue
            seen[key] = True
            keep_hidden.append(vec)
            keep_features.append(feat)
        if keep_hidden:
            hidden = np.stack(keep_hidden, axis=0)
            features = np.stack(keep_features, axis=0)

    return hidden, features


def compute_mutual_info(
    hidden: np.ndarray,
    feature_values: np.ndarray,
    feature_name: str,
) -> Tuple[float, str]:
    """Compute mean MI across all dimensions."""
    try:
        if feature_name in CLASSIFICATION_FEATURES:
            y = feature_values.astype(int)
            classes = np.unique(y)
            if classes.size < 2:
                return float("nan"), "classification"
            mi = mutual_info_classif(hidden, y, random_state=0)
            return float(mi.mean()), "classification"
        else:
            y = feature_values.astype(float)
            if np.allclose(y, y[0]):
                return float("nan"), "regression"
            mi = mutual_info_regression(hidden, y, random_state=0)
            return float(mi.mean()), "regression"
    except Exception as e:
        print(f"[MI] Error computing MI for feature '{feature_name}': {e}")
        return float("nan"), ("classification" if feature_name in CLASSIFICATION_FEATURES else "regression")


def compute_per_dimension_mi(
    hidden: np.ndarray,
    feature_values: np.ndarray,
    feature_name: str,
) -> Tuple[np.ndarray, str]:
    """
    Compute MI for each individual hidden dimension.

    Returns:
        mi_per_dim: Array of shape (hidden_size,) with MI for each dimension
        mi_type: "classification" or "regression"
    """
    try:
        if feature_name in CLASSIFICATION_FEATURES:
            y = feature_values.astype(int)
            classes = np.unique(y)
            if classes.size < 2:
                return np.full(hidden.shape[1], np.nan), "classification"
            mi = mutual_info_classif(hidden, y, random_state=0)
            return mi, "classification"
        else:
            y = feature_values.astype(float)
            if np.allclose(y, y[0]):
                return np.full(hidden.shape[1], np.nan), "regression"
            mi = mutual_info_regression(hidden, y, random_state=0)
            return mi, "regression"
    except Exception as e:
        print(f"[MI] Error computing per-dim MI for feature '{feature_name}': {e}")
        return np.full(hidden.shape[1], np.nan), ("classification" if feature_name in CLASSIFICATION_FEATURES else "regression")


def plot_final_epoch_heatmap(df: pd.DataFrame, output_path: Path) -> None:
    latest = df[df["epoch"] == df.groupby("model")["epoch"].transform("max")]
    pivot = latest.pivot_table(
        index="feature",
        columns="model",
        values="mi",
    )
    plt.figure(figsize=(max(6, pivot.shape[1] * 0.7), max(4, pivot.shape[0] * 0.6)))
    sns.heatmap(
        pivot,
        annot=True,
        annot_kws={"size": 8},
        fmt=".3f",
        cmap="magma",
        cbar_kws={"label": "Mutual Information"},
    )
    plt.title("Hidden State Mutual Information (final epoch)")
    plt.xlabel("Model")
    plt.ylabel("Feature")
    plt.tight_layout()
    output_path.parent.mkdir(parents=True, exist_ok=True)
    plt.savefig(output_path, dpi=300)
    plt.close()


def plot_best_epoch_heatmap(df: pd.DataFrame, analysis_dir: Path, output_path: Path) -> None:
    """Plot MI heatmap at each model's best validation epoch (based on checkpoints history)."""
    # Determine best epoch per model
    models = sorted(df["model"].unique())
    best_epochs: Dict[str, int] = {}
    # Available epochs per model from df
    avail_by_model: Dict[str, List[int]] = {
        m: sorted(df[df["model"] == m]["epoch"].unique().tolist()) for m in models
    }
    for m in models:
        be, _ = _load_training_history_best_saved_epoch(m, analysis_dir)
        if be is None:
            continue
        avail = avail_by_model.get(m, [])
        if not avail:
            continue
        if int(be) in avail:
            best_epochs[m] = int(be)
        else:
            # Snap to nearest available epoch in df
            best_epochs[m] = int(min(avail, key=lambda e: abs(e - int(be))))
    if not best_epochs:
        print("[MI] No best epochs found; skipping best-epoch heatmap.")
        return
    # Select rows matching best epoch per model
    parts = []
    for m, e in best_epochs.items():
        sub = df[(df["model"] == m) & (df["epoch"] == e)]
        if not sub.empty:
            parts.append(sub)
    if not parts:
        print("[MI] No MI rows match best epochs; skipping best-epoch heatmap.")
        return
    best_df = pd.concat(parts, ignore_index=True)
    pivot = best_df.pivot_table(index="feature", columns="model", values="mi")
    plt.figure(figsize=(max(6, pivot.shape[1] * 0.7), max(4, pivot.shape[0] * 0.6)))
    sns.heatmap(
        pivot,
        annot=True,
        annot_kws={"size": 8},
        fmt=".3f",
        cmap="magma",
        cbar_kws={"label": "Mutual Information"},
    )
    plt.title("Hidden State Mutual Information (best val epoch)")
    plt.xlabel("Model")
    plt.ylabel("Feature")
    plt.tight_layout()
    output_path.parent.mkdir(parents=True, exist_ok=True)
    plt.savefig(output_path, dpi=300)
    plt.close()


def plot_feature_trends(df: pd.DataFrame, features: Iterable[str], output_dir: Path) -> None:
    sns.set_style("whitegrid")
    num_features = len(list(features))
    cols = min(3, num_features)
    rows = int(np.ceil(num_features / cols)) if num_features else 1

    # Ensure consistent color mapping and a single, clear legend
    hue_order = sorted(df["model"].unique()) if "model" in df.columns else None
    palette = sns.color_palette(n_colors=len(hue_order)) if hue_order is not None else None

    fig, axes = plt.subplots(rows, cols, figsize=(5 * cols, 3.5 * rows), squeeze=False)
    first_ax_with_legend = None
    last_idx = -1
    for idx, feature in enumerate(features):
        ax = axes[idx // cols][idx % cols]
        subset = df[df["feature"] == feature]
        if subset.empty:
            ax.set_title(feature)
            ax.text(0.5, 0.5, "No data", ha="center", va="center")
            ax.axis("off")
            continue
        # Put a legend only on the first populated subplot; we'll lift it to figure-level later
        show_legend = first_ax_with_legend is None
        sns.lineplot(
            data=subset,
            x="epoch",
            y="mi",
            hue="model",
            hue_order=hue_order,
            palette=palette,
            ax=ax,
            legend=show_legend,
        )
        if show_legend:
            first_ax_with_legend = ax
        ax.set_title(feature)
        ax.set_ylabel("Mutual Information")
        ax.set_xlabel("Epoch")
        last_idx = idx

    # Turn off any unused subplots
    for extra in range((last_idx + 1), rows * cols):
        ax = axes[extra // cols][extra % cols]
        ax.axis("off")

    # Promote the legend from the first axis to a single, shared figure-level legend
    if first_ax_with_legend is not None and first_ax_with_legend.get_legend() is not None:
        handles, labels = first_ax_with_legend.get_legend_handles_labels()
        # Remove automatic title like "model" from axes legend by deleting it
        first_ax_with_legend.legend_.remove()
        ncols = min(4, len(labels)) if labels else 1
        fig.legend(
            handles,
            labels,
            loc="upper center",
            bbox_to_anchor=(0.5, 1.02),
            ncol=ncols,
            frameon=False,
            title="Model",
        )
        # Make room for the legend above
        fig.tight_layout(rect=[0, 0, 1, 0.96])
    else:
        fig.tight_layout()

    output_path = output_dir / "mi_trends.png"
    fig.savefig(output_path, dpi=300)
    plt.close(fig)


def plot_per_dimension_mi_heatmaps(
    per_dim_data: Dict[str, Dict[str, np.ndarray]],
    features: List[str],
    output_dir: Path,
) -> None:
    """
    Plot heatmaps showing which hidden dimensions have highest MI with each feature.

    Args:
        per_dim_data: Dict[model_name][feature_name] -> MI array of shape (hidden_size,)
        features: List of feature names to plot
        output_dir: Where to save plots
    """
    for model_name, feature_mis in per_dim_data.items():
        # Build matrix: features × dimensions
        available_features = [f for f in features if f in feature_mis]
        if not available_features:
            continue

        hidden_size = list(feature_mis.values())[0].shape[0]
        mi_matrix = np.zeros((len(available_features), hidden_size))

        for i, feature in enumerate(available_features):
            mi_matrix[i, :] = feature_mis[feature]

        # Create heatmap
        fig, ax = plt.subplots(figsize=(max(10, hidden_size // 8), max(6, len(available_features) * 0.5)))
        sns.heatmap(
            mi_matrix,
            yticklabels=available_features,
            xticklabels=range(hidden_size) if hidden_size <= 32 else False,
            cmap="viridis",
            cbar_kws={"label": "Mutual Information"},
            ax=ax,
        )
        ax.set_xlabel("Hidden Dimension Index")
        ax.set_ylabel("Feature")
        ax.set_title(f"Per-Dimension MI: {model_name}")

        # Annotate top dimensions
        for feat_idx, feature in enumerate(available_features):
            top_dim = np.argmax(mi_matrix[feat_idx, :])
            top_mi = mi_matrix[feat_idx, top_dim]
            if not np.isnan(top_mi):
                ax.text(
                    top_dim,
                    feat_idx,
                    "★",
                    ha="center",
                    va="center",
                    color="red",
                    fontsize=12,
                    weight="bold",
                )

        plt.tight_layout()
        safe_name = model_name.replace("/", "_")
        output_path = output_dir / f"mi_per_dimension_{safe_name}.png"
        plt.savefig(output_path, dpi=300)
        plt.close(fig)
        print(f"Saved per-dimension heatmap: {output_path}")


def plot_high_mi_dimension_values(
    hidden_samples: Dict[str, Dict[str, Tuple[np.ndarray, np.ndarray, np.ndarray]]],
    features: List[str],
    output_dir: Path,
) -> None:
    """
    Plot actual values in the highest-MI dimension for each feature.

    Args:
        hidden_samples: Dict[model_name][feature_name] -> (hidden, feature_values, mi_per_dim)
        features: List of feature names
        output_dir: Where to save plots
    """
    for model_name, feature_data in hidden_samples.items():
        available_features = [f for f in features if f in feature_data]
        if not available_features:
            continue

        num_features = len(available_features)
        cols = min(3, num_features)
        rows = int(np.ceil(num_features / cols)) if num_features else 1

        fig, axes = plt.subplots(rows, cols, figsize=(5 * cols, 3.5 * rows), squeeze=False)

        for idx, feature in enumerate(available_features):
            ax = axes[idx // cols][idx % cols]
            hidden, feature_vals, mi_per_dim = feature_data[feature]

            # Find dimension with highest MI
            if np.all(np.isnan(mi_per_dim)):
                ax.set_title(feature)
                ax.text(0.5, 0.5, "No valid MI", ha="center", va="center")
                ax.axis("off")
                continue

            best_dim = np.nanargmax(mi_per_dim)
            best_mi = mi_per_dim[best_dim]
            dim_values = hidden[:, best_dim]

            # Plot based on feature type
            if feature in CLASSIFICATION_FEATURES:
                # Box plot or violin plot for categorical
                plot_data = pd.DataFrame({
                    "dimension_value": dim_values,
                    "feature": feature_vals.astype(int),
                })
                # Use hue matching x to enable palette without triggering FutureWarning, then remove legend.
                sns.violinplot(
                    data=plot_data,
                    x="feature",
                    y="dimension_value",
                    hue="feature",
                    ax=ax,
                    palette="Set2",
                    dodge=False,
                )
                # Remove redundant legend created by hue
                leg = ax.get_legend()
                if leg is not None:
                    leg.remove()
                ax.set_xlabel(f"{feature}")
                ax.set_ylabel(f"Dim {best_dim} value")
            else:
                # Scatter plot for continuous
                ax.scatter(feature_vals, dim_values, alpha=0.3, s=10)
                ax.set_xlabel(f"{feature}")
                ax.set_ylabel(f"Dim {best_dim} value")

            ax.set_title(f"{feature}\nBest dim: {best_dim} (MI={best_mi:.3f})")

        # Turn off unused subplots
        for extra in range(num_features, rows * cols):
            ax = axes[extra // cols][extra % cols]
            ax.axis("off")

        fig.suptitle(f"High-MI Dimension Values: {model_name}", fontsize=14)
        fig.tight_layout(rect=[0, 0.02, 1, 0.97])

        safe_name = model_name.replace("/", "_")
        output_path = output_dir / f"mi_dimension_values_{safe_name}.png"
        plt.savefig(output_path, dpi=300)
        plt.close(fig)
        print(f"Saved dimension value plot: {output_path}")


def main() -> None:
    args = parse_args()
    analysis_dir = Path(args.analysis_dir)
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    rng = np.random.default_rng(args.seed)

    rows: List[Dict[str, object]] = []

    # Track per-dimension MI and hidden samples for plots (final and best)
    per_dim_mi_data: Dict[str, Dict[str, np.ndarray]] = {}  # model -> feature -> mi_array (final)
    hidden_samples_data: Dict[str, Dict[str, Tuple[np.ndarray, np.ndarray, np.ndarray]]] = {}  # model -> feature -> (hidden, feature_vals, mi_per_dim) (final)
    per_dim_mi_data_best: Dict[str, Dict[str, np.ndarray]] = {}  # model -> feature -> mi_array (best)
    hidden_samples_data_best: Dict[str, Dict[str, Tuple[np.ndarray, np.ndarray, np.ndarray]]] = {}  # model -> feature -> (hidden, feature_vals, mi_per_dim) (best)
    model_final_epochs: Dict[str, int] = {}  # Track final epoch per model
    model_best_epochs: Dict[str, int] = {}

    # Precompute task counts for progress/ETA
    model_dirs = sorted(p for p in analysis_dir.iterdir() if p.is_dir())
    per_model_files: Dict[str, List[Tuple[int, Path]]] = {}
    for m in model_dirs:
        per_model_files[m.name] = list_hidden_files(m)
    features = list(args.features)
    total_primary = sum(len(per_model_files[m]) * len(features) for m in per_model_files)
    # Per-dimension MI only at final epoch per model
    total_perdim = len(per_model_files) * len(features)
    total_tasks = max(1, total_primary + total_perdim)
    done = 0
    t0 = time.time()
    interval = max(1, int(args.progress_interval))
    print("[MI] Config:")
    print(f"  analysis-dir      = {analysis_dir}")
    print(f"  output-dir        = {output_dir}")
    print(f"  features          = {features}")
    print(f"  max-samples       = {args.max_samples}")
    print(f"  seed              = {args.seed}")
    print(f"  progress-interval = {interval}")
    print(f"  workers           = {args.workers}")
    print(f"[MI] Starting mutual information analysis: ~{total_tasks} computations (including per-dimension at final epoch)...", flush=True)

    for model_dir in model_dirs:
        model_meta = parse_model_name(model_dir.name)
        hidden_files = per_model_files.get(model_dir.name, [])
        if not hidden_files:
            continue

        # Track final and best epoch for this model
        model_final_epochs[model_dir.name] = max(epoch for epoch, _ in hidden_files)
        best_e, _final_e_from_hist = _load_training_history_best_saved_epoch(model_dir.name, analysis_dir)
        if best_e is not None:
            model_best_epochs[model_dir.name] = int(best_e)

        for epoch, npz_path in hidden_files:
            hidden, features, feature_names = load_hidden_samples(npz_path, args.max_samples, rng)
            if hidden.shape[0] < 5:
                continue
            name_to_idx = {name: idx for idx, name in enumerate(feature_names)}

            is_final_epoch = (epoch == model_final_epochs[model_dir.name])
            is_best_epoch = (model_dir.name in model_best_epochs and epoch == model_best_epochs[model_dir.name])
            # Parallelize MI across features for this (model, epoch)
            with cf.ThreadPoolExecutor(max_workers=args.workers) as executor:
                futures = {}
                for feature in args.features:
                    if feature not in name_to_idx:
                        continue
                    values = features[:, name_to_idx[feature]]
                    futures[executor.submit(compute_mutual_info, hidden, values, feature)] = (feature, values)

                for fut in cf.as_completed(futures):
                    feature, values = futures[fut]
                    mi, mi_type = fut.result()
                    rows.append(
                        {
                            "model": model_dir.name,
                            "epoch": epoch,
                            "feature": feature,
                            "mi": mi,
                            "type": mi_type,
                            **model_meta,
                        }
                    )
                    # Progress update
                    done += 1
                    elapsed = time.time() - t0
                    avg = elapsed / max(1, done)
                    remaining = max(0, total_tasks - done)
                    eta_min = (remaining * avg) / 60.0
                    if done <= interval or done % interval == 0:
                        print(f"[MI] {done}/{total_tasks} | {model_dir.name} | epoch={epoch} | feature={feature} | ETA~{eta_min:.1f}m", flush=True)

                    if is_final_epoch or is_best_epoch:
                        # Per-dimension MI (can also be parallelized, but compute inline to avoid memory blowup)
                        mi_per_dim, _ = compute_per_dimension_mi(hidden, values, feature)
                        if is_final_epoch:
                            if model_dir.name not in per_dim_mi_data:
                                per_dim_mi_data[model_dir.name] = {}
                            per_dim_mi_data[model_dir.name][feature] = mi_per_dim
                            if model_dir.name not in hidden_samples_data:
                                hidden_samples_data[model_dir.name] = {}
                            hidden_samples_data[model_dir.name][feature] = (hidden, values, mi_per_dim)
                        if is_best_epoch:
                            if model_dir.name not in per_dim_mi_data_best:
                                per_dim_mi_data_best[model_dir.name] = {}
                            per_dim_mi_data_best[model_dir.name][feature] = mi_per_dim
                            if model_dir.name not in hidden_samples_data_best:
                                hidden_samples_data_best[model_dir.name] = {}
                            hidden_samples_data_best[model_dir.name][feature] = (hidden, values, mi_per_dim)
                        done += 1
                        elapsed = time.time() - t0
                        avg = elapsed / max(1, done)
                        remaining = max(0, total_tasks - done)
                        eta_min = (remaining * avg) / 60.0
                        if done % interval == 0:
                            which = "final" if is_final_epoch else ("best" if is_best_epoch else "")
                            print(f"[MI] per-dim {done}/{total_tasks} | {model_dir.name} | epoch={epoch} ({which}) | feature={feature} | ETA~{eta_min:.1f}m", flush=True)

    if not rows:
        print("No mutual information results computed.")
        return

    df = pd.DataFrame(rows)
    df.sort_values(["model", "feature", "epoch"], inplace=True)
    csv_path = output_dir / "mi_results.csv"
    df.to_csv(csv_path, index=False)
    print(f"Saved MI results to {csv_path}")

    # Generate existing plots
    plot_final_epoch_heatmap(df, output_dir / "mi_heatmap_final.png")
    # New: best-epoch heatmap (per model based on checkpoints history)
    plot_best_epoch_heatmap(df, analysis_dir, output_dir / "mi_heatmap_best.png")
    plot_feature_trends(df, args.features, output_dir)

    # Generate new per-dimension plots
    print("\nGenerating per-dimension MI heatmaps...")
    plot_per_dimension_mi_heatmaps(per_dim_mi_data, args.features, output_dir)
    if per_dim_mi_data_best:
        # Save into a subfolder to avoid clobbering final-epoch plots
        best_dir = output_dir / "best_epoch"
        best_dir.mkdir(parents=True, exist_ok=True)
        plot_per_dimension_mi_heatmaps(per_dim_mi_data_best, args.features, best_dir)

    print("\nGenerating high-MI dimension value plots...")
    plot_high_mi_dimension_values(hidden_samples_data, args.features, output_dir)
    if hidden_samples_data_best:
        best_dir = output_dir / "best_epoch"
        best_dir.mkdir(parents=True, exist_ok=True)
        plot_high_mi_dimension_values(hidden_samples_data_best, args.features, best_dir)

    summary = {
        "analysis_dir": str(analysis_dir),
        "features": args.features,
        "max_samples": args.max_samples,
        "seed": args.seed,
        "output_dir": str(output_dir),
    }
    (output_dir / "mi_metadata.json").write_text(json.dumps(summary, indent=2))
    print(f"\nAll analyses complete. Outputs in {output_dir}")


if __name__ == "__main__":
    main()
